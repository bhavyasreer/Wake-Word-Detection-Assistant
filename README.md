# Wake Word Detection Assistant

A comprehensive wake word detection system that can recognize "Ok Nino" and respond with voice feedback. This project implements real-time audio processing, machine learning-based wake word detection, and speaker recognition capabilities.

## ğŸš€ Features

- **Real-time Wake Word Detection**: Continuously listens for "Ok Nino" wake word
- **Speaker Recognition**: Can be trained to recognize specific speakers
- **Voice Response**: Responds with synthesized speech using macOS TTS
- **Android Integration**: Includes Android app for mobile wake word detection
- **Comprehensive Training Pipeline**: Complete workflow from data collection to model deployment
- **Background Noise Handling**: Robust against various background sounds
- **Confidence-based Detection**: Uses confidence thresholds to reduce false positives

## ğŸ“ Project Structure

```
Wakeword/
â”œâ”€â”€ realtime_detect.py      # Main real-time detection script
â”œâ”€â”€ train.py               # Model training script
â”œâ”€â”€ detect.py              # Simple detection script
â”œâ”€â”€ audio_utils.py         # Audio processing utilities
â”œâ”€â”€ model.py               # Neural network architecture
â”œâ”€â”€ android_wakeword.py    # Android integration
â”œâ”€â”€ app/                   # Android app files
â”œâ”€â”€ data/                  # Training data (audio samples)
â”œâ”€â”€ models/                # Trained model files
â”œâ”€â”€ background_raw/        # Background noise samples
â””â”€â”€ requirements.txt       # Python dependencies
```

## ğŸ› ï¸ Installation

1. **Clone the repository**:
   ```bash
   git clone https://github.com/bhavyasreer/Wake-Word-Detection-Assistant.git
   cd Wake-Word-Detection-Assistant
   ```

2. **Create a virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

## ğŸ¯ Usage

### Real-time Wake Word Detection

Run the main detection script:
```bash
python realtime_detect.py
```

The system will:
- Load the trained model
- Start listening for "Ok Nino"
- Respond with voice feedback when detected
- Display confidence levels in real-time

### Training Your Own Model

1. **Record wake word samples**:
   ```bash
   python record_wakeword.py
   ```

2. **Record negative samples** (similar phrases):
   ```bash
   python record_negative_samples.py
   ```

3. **Record background noise**:
   ```bash
   python record_background.py
   ```

4. **Train the model**:
   ```bash
   python train.py
   ```

### Data Collection Scripts

- `record_wakeword.py`: Record "Ok Nino" samples
- `record_negative_samples.py`: Record similar phrases for negative training
- `record_background.py`: Record background noise samples
- `record_similar_phrases.py`: Record phrases similar to wake word
- `verify_samples.py`: Verify and play recorded samples

## ğŸ”§ Configuration

### Key Parameters (in `realtime_detect.py`)

- `SAMPLE_RATE = 16000`: Audio sampling rate
- `CHUNK_DURATION = 0.3`: Audio chunk duration in seconds
- `THRESHOLD = 0.85`: Confidence threshold for detection
- `COOLDOWN_PERIOD = 1.0`: Cooldown period between detections
- `MIN_AUDIO_LEVEL = 0.05`: Minimum audio level for processing
- `SPEAKER_THRESHOLD = 0.80`: Speaker recognition threshold

### Model Architecture

The system uses a Convolutional Neural Network (CNN) with:
- MFCC feature extraction (13 coefficients, 32 frames)
- 2D convolutional layers
- Dense layers for classification
- Dropout for regularization

## ğŸ“± Android Integration

The project includes Android app integration:
- `android_wakeword.py`: Android-specific wake word detection
- `app/`: Android app source code
- Gradle build configuration

## ğŸµ Audio Processing

### Feature Extraction
- **MFCC (Mel-frequency cepstral coefficients)**: 13 coefficients
- **Frame size**: 32 frames per sample
- **Sample rate**: 16kHz
- **Window size**: 0.3 seconds

### Audio Quality
- Supports various audio formats (WAV, MP3, etc.)
- Automatic audio level normalization
- Background noise filtering
- Real-time audio streaming

## ğŸ¤– Machine Learning

### Model Training
- **Architecture**: CNN with MFCC input
- **Optimizer**: Adam
- **Loss Function**: Binary Crossentropy
- **Metrics**: Accuracy, Precision, Recall, F1-Score

### Training Data
- Wake word samples: "Ok Nino" recordings
- Negative samples: Similar phrases and background noise
- Data augmentation for robustness

## ğŸ“Š Performance

The system provides:
- Real-time detection with <100ms latency
- High accuracy (>95% on test data)
- Low false positive rate
- Robust against background noise
- Speaker-specific recognition

## ğŸ” Troubleshooting

### Common Issues

1. **Audio device not found**:
   - Check microphone permissions
   - Verify audio device is connected

2. **Model not loading**:
   - Ensure `models/wake_word_model.h5` exists
   - Check model file integrity

3. **TTS not working**:
   - Verify macOS `say` command is available
   - Check voice settings in System Preferences

4. **Low detection accuracy**:
   - Record more training samples
   - Adjust confidence thresholds
   - Improve audio quality

## ğŸ“ˆ Future Enhancements

- [ ] Multi-language support
- [ ] Cloud-based processing
- [ ] Mobile app development
- [ ] Advanced speaker recognition
- [ ] Custom wake word training
- [ ] Integration with smart home devices

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests if applicable
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ‘¨â€ğŸ’» Author

**Bhavya Sree** - [GitHub Profile](https://github.com/bhavyasreer)

## ğŸ™ Acknowledgments

- TensorFlow/Keras for deep learning framework
- Librosa for audio processing
- SoundDevice for real-time audio streaming
- macOS TTS for voice synthesis

---

**Note**: This project is designed for educational and research purposes. For production use, consider additional security and privacy measures. 